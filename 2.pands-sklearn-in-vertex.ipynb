{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28d5a597-2658-4c2e-bdda-944c2dab87ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/vertex-ai-samples/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0422 19:03:55.498913995   26965 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e92f9-980b-43e9-8c76-b2aa02260e96",
   "metadata": {},
   "source": [
    "# Sklearn with Pandas\n",
    "\n",
    "This is similar to the other notebook except we will be using pandas and bigquery\n",
    "Topics covered\n",
    "* Training sklearn locally, deploying to endpoint\n",
    "* Saving data as CSV and doing batch predict from GCS\n",
    "* Loading data to BQ, using BQ magics\n",
    "* Running a batch prediction from BQ to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cbe8a06-ed15-40ac-bc2f-d387bb406301",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'YOUR-PROJECT' #SET THIS TO YOUR PROJECT ID\n",
    "BUCKET = \"gs://YOUR-BUCKET\" #BE SURE TO gsutil mb -l <REGION> <LOG_BUCKET> to create the bucket on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb15f1f6-9bc5-4e82-9c4f-3f9c33882868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "import pandas as pd\n",
    "import numpy as np #for the random integer example\n",
    "df = pd.DataFrame(np.random.randint(0.0,100.0,size=(10,4)),\n",
    "              index=range(10,20),\n",
    "              columns=['col1','col2','col3','label'],\n",
    "              dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13825936-816a-4b3f-a624-7c7684fc7c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>67.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>59.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col1  col2  col3  label\n",
       "10  62.0  35.0   3.0   79.0\n",
       "11   9.0  14.0  56.0   52.0\n",
       "12  46.0  80.0  68.0   95.0\n",
       "13  15.0  92.0   9.0    7.0\n",
       "14  67.0  64.0  38.0   17.0\n",
       "15  79.0  68.0  73.0   99.0\n",
       "16  47.0  61.0  50.0   37.0\n",
       "17  59.0  35.0  57.0   38.0\n",
       "18   4.0  35.0  63.0   29.0\n",
       "19  56.0  96.0  62.0   46.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0849f09-5f48-4e73-96db-c2fa53c06ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=6, max_features=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Set the model parameters. \n",
    "n_estimators = 100\n",
    "max_depth = 6\n",
    "max_features = 3\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "rf.fit(df[['col1', 'col2', 'col3']], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d32fb67-b6f8-40fc-b335-95c41c2c3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "artifact_filename = 'pandas_model_test.pkl'\n",
    "\n",
    "# Save model artifact to local filesystem (doesn't persist)\n",
    "local_path = artifact_filename\n",
    "with open(local_path, 'wb') as model_file:\n",
    "    pickle.dump(rf, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703dce1-9998-483b-9269-56c7e3ce72dc",
   "metadata": {},
   "source": [
    "## Upload the model to Vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d8e71d-9702-4c7d-bd15-925278f759d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/633325234048/locations/us-central1/models/2404029397574090752/operations/769929237778923520\n",
      "Model created. Resource name: projects/633325234048/locations/us-central1/models/2404029397574090752\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/633325234048/locations/us-central1/models/2404029397574090752')\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "model = aiplatform.Model.upload_scikit_learn_model_file(\n",
    "        display_name='pandas test',\n",
    "        model_file_path=local_path,\n",
    "        description='pandas test for deploying models to vertex',\n",
    "        sync=False, #this will not bind up your notebook instance with the creation operation\n",
    "    ) #note this will automatcially designate the latest sklearn serving container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7e030-a234-40ad-8c8d-bc0ece95d93f",
   "metadata": {},
   "source": [
    "### Now we will create a different dataframe to make predictions on for batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8328221-1c7c-4c65-bf71-59b59b75a7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.75      , 80.7       , 82.95      , 82.03      , 88.81      ,\n",
       "       35.02833333, 82.36      , 89.93      , 50.6       , 44.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0.0,100.0,size=(10,3)), # we will do batch predictions based on this\n",
    "              index=range(10,20),\n",
    "              columns=['col1','col2','col3'],\n",
    "              dtype='float64')\n",
    "rf.predict(df2[['col1','col2','col3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98f67d-b47e-43de-a41e-0e927bff6e43",
   "metadata": {},
   "source": [
    "### Exepected output\n",
    "From documentation:\n",
    "```\n",
    "    \"input1\",\"input2\",\"input3\"\n",
    "    0.1,1.2,3.0\n",
    "    4.0,5.0,6.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4994f47d-37e8-4992-9c38-762a713818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import csv\n",
    "\n",
    "# save the csv with the header, no index\n",
    "df2.to_csv('df2.csv', index=False)#, quoting=csv.QUOTE_ALL) #quotenonumeric to get header quotes\n",
    "\n",
    "data_directory = BUCKET + \"/data\"\n",
    "storage_path = os.path.join(data_directory, 'df2.csv')\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())\n",
    "blob.upload_from_filename(\"df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6e9726a-b234-4e56-97ba-a6df579fec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/633325234048/locations/us-central1/batchPredictionJobs/1196121866217979904\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/633325234048/locations/us-central1/batchPredictionJobs/1196121866217979904')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/1196121866217979904?project=633325234048\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/1196121866217979904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/1196121866217979904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/1196121866217979904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/1196121866217979904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/1196121866217979904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "        job_display_name='pandas batch predict job sklearn',\n",
    "        gcs_source=storage_path,\n",
    "        gcs_destination_prefix=BUCKET+\"/predictions\",\n",
    "        machine_type='n1-standard-2',\n",
    "        instances_format='csv', #This is key to parsing CSV input\n",
    "        # accelerator_count=accelerator_count,\n",
    "        # accelerator_type=accelerator_type, #if you want gpus\n",
    "        starting_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        sync=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3e3b11a-4536-4ad8-89eb-596f1cb00801",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_gbq\n",
      "  Downloading pandas_gbq-0.17.4-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: pyarrow<8.0dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from pandas_gbq) (7.0.0)\n",
      "Collecting pydata-google-auth\n",
      "  Downloading pydata_google_auth-1.4.0-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from pandas_gbq) (2.13.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from pandas_gbq) (59.8.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2 in /opt/conda/lib/python3.7/site-packages (from pandas_gbq) (2.34.2)\n",
      "Collecting db-dtypes<2.0.0,>=0.3.1\n",
      "  Downloading db_dtypes-1.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from pandas_gbq) (0.4.6)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from pandas_gbq) (2.5.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/conda/lib/python3.7/site-packages (from pandas_gbq) (1.3.5)\n",
      "Requirement already satisfied: google-auth>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from pandas_gbq) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pandas_gbq) (1.21.5)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from db-dtypes<2.0.0,>=0.3.1->pandas_gbq) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (1.54.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (3.19.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.25.0->pandas_gbq) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.25.0->pandas_gbq) (0.2.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.25.0->pandas_gbq) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.25.0->pandas_gbq) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib>=0.0.1->pandas_gbq) (1.3.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.3.2)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.20.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.2.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.44.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.2->pandas_gbq) (2021.3)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (1.44.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->db-dtypes<2.0.0,>=0.3.1->pandas_gbq) (3.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.25.0->pandas_gbq) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (1.26.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.0.1->pandas_gbq) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.21)\n",
      "Installing collected packages: db-dtypes, pydata-google-auth, pandas_gbq\n",
      "Successfully installed db-dtypes-1.0.0 pandas_gbq-0.17.4 pydata-google-auth-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_gbq --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f618374-344b-4b0c-84de-c044db48fd88",
   "metadata": {},
   "source": [
    "## Create an empty dataset to house the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3134e415-e681-40cc-b002-b7b2b8f047dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'wortz-project:TEST' successfully created.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=location mk \\\n",
    "--dataset \\\n",
    "--description \"test dataset\" \\\n",
    "--location \"US\" \\\n",
    "$PROJECT_ID:TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7e94a22-cc73-486b-9a80-de49e9b5b839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1704.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the table to BQ and make Batch predictions\n",
    "from pandas_gbq import to_gbq\n",
    "\n",
    "df2.to_gbq(destination_table=f\"{PROJECT_ID}.TEST.df2\", project_id=PROJECT_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c86c3-013b-4679-b75e-c26b76e4d743",
   "metadata": {},
   "source": [
    "## Bigquery magic comes available by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4acea4a-b0ec-42fa-9eaa-04d80d5d14c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 579.56query/s]                          \n",
      "Downloading: 100%|██████████| 10/10 [00:01<00:00,  7.76rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>98.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3\n",
       "0  20.0  12.0  62.0\n",
       "1  14.0  18.0  79.0\n",
       "2  56.0  19.0  81.0\n",
       "3  58.0  91.0  74.0\n",
       "4  77.0  49.0  99.0\n",
       "5  50.0  26.0  38.0\n",
       "6  49.0  23.0  69.0\n",
       "7  78.0  23.0  96.0\n",
       "8  98.0  36.0  15.0\n",
       "9  79.0  82.0  33.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/1196121866217979904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "%%bigquery\n",
    "select * from TEST.df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4a7df-a0bb-4e8a-b6f8-df1f8392b9ce",
   "metadata": {},
   "source": [
    "## Now run batch predicitons on this bq table\n",
    "\n",
    "Note you have to have write permissions on the dataset - you may see a error if you don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c37fa5e-1308-4c6c-9a21-e0d340ff9a8e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mjob_display_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgcs_source\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbigquery_source\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minstances_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jsonl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgcs_destination_prefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbigquery_destination_prefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpredictions_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jsonl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel_parameters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmachine_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maccelerator_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maccelerator_count\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstarting_replica_count\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_replica_count\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgenerate_explanation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexplanation_metadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maiplatform_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplanation_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplanationMetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexplanation_parameters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maiplatform_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplanationParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcredentials\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencryption_spec_key_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msync\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchPredictionJob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Creates a batch prediction job using this Model and outputs\n",
       "prediction results to the provided destination prefix in the specified\n",
       "`predictions_format`. One source and one destination prefix are\n",
       "required.\n",
       "\n",
       "Example usage:\n",
       "\n",
       "my_model.batch_predict(\n",
       "    job_display_name=\"prediction-123\",\n",
       "    gcs_source=\"gs://example-bucket/instances.csv\",\n",
       "    instances_format=\"csv\",\n",
       "    bigquery_destination_prefix=\"projectId.bqDatasetId.bqTableId\"\n",
       ")\n",
       "\n",
       "Args:\n",
       "    job_display_name (str):\n",
       "        Optional. The user-defined name of the BatchPredictionJob.\n",
       "        The name can be up to 128 characters long and can be consist\n",
       "        of any UTF-8 characters.\n",
       "    gcs_source: Optional[Sequence[str]] = None\n",
       "        Google Cloud Storage URI(-s) to your instances to run\n",
       "        batch prediction on. They must match `instances_format`.\n",
       "        May contain wildcards. For more information on wildcards, see\n",
       "        https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.\n",
       "    bigquery_source: Optional[str] = None\n",
       "        BigQuery URI to a table, up to 2000 characters long. For example:\n",
       "        `bq://projectId.bqDatasetId.bqTableId`\n",
       "    instances_format: str = \"jsonl\"\n",
       "        The format in which instances are provided. Must be one\n",
       "        of the formats listed in `Model.supported_input_storage_formats`.\n",
       "        Default is \"jsonl\" when using `gcs_source`. If a `bigquery_source`\n",
       "        is provided, this is overridden to \"bigquery\".\n",
       "    gcs_destination_prefix: Optional[str] = None\n",
       "        The Google Cloud Storage location of the directory where the\n",
       "        output is to be written to. In the given directory a new\n",
       "        directory is created. Its name is\n",
       "        ``prediction-<model-display-name>-<job-create-time>``, where\n",
       "        timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format.\n",
       "        Inside of it files ``predictions_0001.<extension>``,\n",
       "        ``predictions_0002.<extension>``, ...,\n",
       "        ``predictions_N.<extension>`` are created where\n",
       "        ``<extension>`` depends on chosen ``predictions_format``,\n",
       "        and N may equal 0001 and depends on the total number of\n",
       "        successfully predicted instances. If the Model has both\n",
       "        ``instance`` and ``prediction`` schemata defined then each such\n",
       "        file contains predictions as per the ``predictions_format``.\n",
       "        If prediction for any instance failed (partially or\n",
       "        completely), then an additional ``errors_0001.<extension>``,\n",
       "        ``errors_0002.<extension>``,..., ``errors_N.<extension>``\n",
       "        files are created (N depends on total number of failed\n",
       "        predictions). These files contain the failed instances, as\n",
       "        per their schema, followed by an additional ``error`` field\n",
       "        which as value has ```google.rpc.Status`` <Status>`__\n",
       "        containing only ``code`` and ``message`` fields.\n",
       "    bigquery_destination_prefix: Optional[str] = None\n",
       "        The BigQuery URI to a project or table, up to 2000 characters long.\n",
       "        When only the project is specified, the Dataset and Table is created.\n",
       "        When the full table reference is specified, the Dataset must exist and\n",
       "        table must not exist. Accepted forms: ``bq://projectId`` or\n",
       "        ``bq://projectId.bqDatasetId`` or\n",
       "        ``bq://projectId.bqDatasetId.bqTableId``. If no Dataset is specified,\n",
       "        a new one is created with the name\n",
       "        ``prediction_<model-display-name>_<job-create-time>``\n",
       "        where the table name is made BigQuery-dataset-name compatible\n",
       "        (for example, most special characters become underscores), and\n",
       "        timestamp is in YYYY_MM_DDThh_mm_ss_sssZ \"based on ISO-8601\"\n",
       "        format. In the dataset two tables will be created, ``predictions``,\n",
       "        and ``errors``. If the Model has both ``instance`` and\n",
       "        ``prediction`` schemata defined then the tables have columns as\n",
       "        follows: The ``predictions`` table contains instances for which\n",
       "        the prediction succeeded, it has columns as per a concatenation\n",
       "        of the Model's instance and prediction schemata. The ``errors``\n",
       "        table contains rows for which the prediction has failed, it has\n",
       "        instance columns, as per the instance schema, followed by a single\n",
       "        \"errors\" column, which as values has ```google.rpc.Status`` <Status>`__\n",
       "        represented as a STRUCT, and containing only ``code`` and ``message``.\n",
       "    predictions_format: str = \"jsonl\"\n",
       "        Required. The format in which Vertex AI outputs the\n",
       "        predictions, must be one of the formats specified in\n",
       "        `Model.supported_output_storage_formats`.\n",
       "        Default is \"jsonl\" when using `gcs_destination_prefix`. If a\n",
       "        `bigquery_destination_prefix` is provided, this is overridden to\n",
       "        \"bigquery\".\n",
       "    model_parameters: Optional[Dict] = None\n",
       "        Optional. The parameters that govern the predictions. The schema of\n",
       "        the parameters may be specified via the Model's `parameters_schema_uri`.\n",
       "    machine_type: Optional[str] = None\n",
       "        Optional. The type of machine for running batch prediction on\n",
       "        dedicated resources. Not specifying machine type will result in\n",
       "        batch prediction job being run with automatic resources.\n",
       "    accelerator_type: Optional[str] = None\n",
       "        Optional. The type of accelerator(s) that may be attached\n",
       "        to the machine as per `accelerator_count`. Only used if\n",
       "        `machine_type` is set.\n",
       "    accelerator_count: Optional[int] = None\n",
       "        Optional. The number of accelerators to attach to the\n",
       "        `machine_type`. Only used if `machine_type` is set.\n",
       "    starting_replica_count: Optional[int] = None\n",
       "        The number of machine replicas used at the start of the batch\n",
       "        operation. If not set, Vertex AI decides starting number, not\n",
       "        greater than `max_replica_count`. Only used if `machine_type` is\n",
       "        set.\n",
       "    max_replica_count: Optional[int] = None\n",
       "        The maximum number of machine replicas the batch operation may\n",
       "        be scaled to. Only used if `machine_type` is set.\n",
       "        Default is 10.\n",
       "    generate_explanation (bool):\n",
       "        Optional. Generate explanation along with the batch prediction\n",
       "        results. This will cause the batch prediction output to include\n",
       "        explanations based on the `prediction_format`:\n",
       "            - `bigquery`: output includes a column named `explanation`. The value\n",
       "                is a struct that conforms to the [aiplatform.gapic.Explanation] object.\n",
       "            - `jsonl`: The JSON objects on each line include an additional entry\n",
       "                keyed `explanation`. The value of the entry is a JSON object that\n",
       "                conforms to the [aiplatform.gapic.Explanation] object.\n",
       "            - `csv`: Generating explanations for CSV format is not supported.\n",
       "    explanation_metadata (explain.ExplanationMetadata):\n",
       "        Optional. Explanation metadata configuration for this BatchPredictionJob.\n",
       "        Can be specified only if `generate_explanation` is set to `True`.\n",
       "\n",
       "        This value overrides the value of `Model.explanation_metadata`.\n",
       "        All fields of `explanation_metadata` are optional in the request. If\n",
       "        a field of the `explanation_metadata` object is not populated, the\n",
       "        corresponding field of the `Model.explanation_metadata` object is inherited.\n",
       "        For more details, see `Ref docs <http://tinyurl.com/1igh60kt>`\n",
       "    explanation_parameters (explain.ExplanationParameters):\n",
       "        Optional. Parameters to configure explaining for Model's predictions.\n",
       "        Can be specified only if `generate_explanation` is set to `True`.\n",
       "\n",
       "        This value overrides the value of `Model.explanation_parameters`.\n",
       "        All fields of `explanation_parameters` are optional in the request. If\n",
       "        a field of the `explanation_parameters` object is not populated, the\n",
       "        corresponding field of the `Model.explanation_parameters` object is inherited.\n",
       "        For more details, see `Ref docs <http://tinyurl.com/1an4zake>`\n",
       "    labels: Optional[Dict[str, str]] = None\n",
       "        Optional. The labels with user-defined metadata to organize your\n",
       "        BatchPredictionJobs. Label keys and values can be no longer than\n",
       "        64 characters (Unicode codepoints), can only contain lowercase\n",
       "        letters, numeric characters, underscores and dashes.\n",
       "        International characters are allowed. See https://goo.gl/xmQnxf\n",
       "        for more information and examples of labels.\n",
       "    credentials: Optional[auth_credentials.Credentials] = None\n",
       "        Optional. Custom credentials to use to create this batch prediction\n",
       "        job. Overrides credentials set in aiplatform.init.\n",
       "    encryption_spec_key_name (Optional[str]):\n",
       "        Optional. The Cloud KMS resource identifier of the customer\n",
       "        managed encryption key used to protect the model. Has the\n",
       "        form:\n",
       "        ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.\n",
       "        The key needs to be in the same region as where the compute\n",
       "        resource is created.\n",
       "\n",
       "        If set, this Model and all sub-resources of this Model will be secured by this key.\n",
       "\n",
       "        Overrides encryption_spec_key_name set in aiplatform.init.\n",
       "    create_request_timeout (float):\n",
       "        Optional. The timeout for the create request in seconds.\n",
       "Returns:\n",
       "    (jobs.BatchPredictionJob):\n",
       "        Instantiated representation of the created batch prediction job.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/models.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?model.batch_predict # Use in-notebook help for help with fields for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fbfc3edb-8a9f-4502-976f-eee7afc3cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/5876487778962767872?project=633325234048\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/633325234048/locations/us-central1/batchPredictionJobs/5876487778962767872\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "        job_display_name='bigquery batch predict job sklearn',\n",
    "        bigquery_source=f\"bq://{PROJECT_ID}.TEST.df2\",\n",
    "        bigquery_destination_prefix=f'bq://{PROJECT_ID}', #this will create a seperate dataset with predictions\n",
    "        machine_type='n1-standard-2',\n",
    "        # accelerator_count=accelerator_count,\n",
    "        # accelerator_type=accelerator_type, #if you want gpus\n",
    "        starting_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        sync=True,\n",
    "    ) \n",
    "\n",
    "# Output table will look something like this:  wortz-project.prediction_pandas_test_2022_04_22T11_32_14_834Z.predictions_2022_04_22T11_32_14_834Z "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34021ec-ce6b-4b9b-a115-a136ce1fb27e",
   "metadata": {},
   "source": [
    "# Other topics to consider\n",
    "* Batch training\n",
    "* Pipeline orchastration"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
